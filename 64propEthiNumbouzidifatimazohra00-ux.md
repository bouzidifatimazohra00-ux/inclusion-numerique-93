# Annotations  


« ve des propo » ([Maurel, p. 3](zotero://select/library/items/IPC997NB)) ([pdf](zotero://open-pdf/library/items/K2ECH5ZN?page=3&annotation=RQTG632C))

« le discours politique, économique et médiatique est empli de références à l’intelligence artificielle, dont il est devenu banal d’affirmer qu’elle doit être « responsable », « éthique », « de confiance ». » ([Maurel, p. 4](zotero://select/library/items/IPC997NB)) ([pdf](zotero://open-pdf/library/items/K2ECH5ZN?page=4&annotation=4FACHJ49)) lauteur ici a commence avec des terme clés qui sont toujours associer a l'IA   
on les  entend  partout maintenant,je trouve ca vrai c'est devenu automatique de dire que l'IA doit être éthique. Par rapport a notre enquete je me pose la question de comment on peut savoir si une entreprise fait vraiment de l'IA éthique ou si elle utilise juste ces mots pour attirer des candidats ou rassurer les partenaires ?

« Un système IA respecterait le principe de dignité si son développement et son usage profitaient au développement humain et que ses coûts sociaux étaient acceptables dans une société donnée » ([Maurel, p. 4](zotero://select/library/items/IPC997NB)) ([pdf](zotero://open-pdf/library/items/K2ECH5ZN?page=4&annotation=KGPU9XWI)) j'ai un peu du mal avec cette idée de "coûts sociaux acceptables". Je ne suis pas d'accord avec cette formulation parce que ça donne l'impression qu'on peut sacrifier l'humain ou créer des inégalités du moment que la société juge que c'est "supportable"alors que nan je trouve que ca va exclure une partie de la societe on peut danner un exmple aussi sur les entreprise et les profiles qui condidate pour un travail

« L’éthique est un questionnement quant à son propre comportement, et même un processus de questionnement. La borner à une série de principes pas toujours clairs à propos desquels il conviendrait de s’interroger ne fait que figer le questionnement, lequel doit au contraire être évolutif. » ([Maurel, p. 5](zotero://select/library/items/IPC997NB)) ([pdf](zotero://open-pdf/library/items/K2ECH5ZN?page=5&annotation=R4KF26YQ)) L'auteur dit que l'éthique ne doit pas être une liste de règles fixes (comme les 10 principes de l'UNESCO), mais une réflexion qui bouge tout le temps. Si on se contente de suivre des principes, on finit par ne plus réfléchir du tout.

« La troisième proposition consiste à tirer les leçons de ce qui précède. Cela consiste essentiellement à ralentir pour réfléchir » ([Maurel, p. 5](zotero://select/library/items/IPC997NB)) ([pdf](zotero://open-pdf/library/items/K2ECH5ZN?page=5&annotation=ZT6BFGTT)) dans la troisieme propostion on voit que l'auteur a  propose de "ralentir", ce qui est l'opposé de ce qu'on voit d'habitude avec l'IA où tout va très vite. C'est courageux de dire qu'il faut prendre le temps de réfléchir au lieu de juste courir après l'innovation

« Incidemment, il s’est donc agi de cibler les meilleurs usages – selon des critères à construire collectivement – et interroger l’intérêt des autres. » ([Maurel, p. 5](zotero://select/library/items/IPC997NB)) ([pdf](zotero://open-pdf/library/items/K2ECH5ZN?page=5&annotation=TIY57CZW)) Ici, on passe à l'action. L'idée de choisir collectivement quels usages de l'IA sont bons et lesquels ne servent à rien est super importante. Ça veut dire qu'on ne doit pas tout accepter juste parce que c'est de la technologie.

« des nouvelles études démontrant de manière peu contestable les méfaits de l’utilisation de l’IA à l’école , ou encore à la mise en service de « Grok », outil d’IA générative intégré au réseau social X et qui s’apparente à la fois à un grouffre économico-énergétique et à un outil de cyberharcèlement ...le tableau n’est guère reluisant. » ([Maurel, p. 6](zotero://select/library/items/IPC997NB)) ([pdf](zotero://open-pdf/library/items/K2ECH5ZN?page=6&annotation=6268FAU9)) Est-ce qu'on n'est pas en train de créer plus de problèmes qu'on n'en résout ?  
autre Si l'IA aggrave la crise climatique, est-ce qu'elle peut vraiment être qualifiée d'"éthique", même si elle respecte quelques principes de base ?

« L’inconvénient d’une telle logique, que l’on retrouve aussi en matière de cybersécurité, est qu’elle fait peser la responsabilité, ou une grande part de responsabilité, sur l’usager et non sur le concepteur » ([Maurel, p. 7](zotero://select/library/items/IPC997NB)) ([pdf](zotero://open-pdf/library/items/K2ECH5ZN?page=7&annotation=WMBMNAG2)) ici je suis pas d'accord avec l'auteur. Je trouve ça injuste. L'auteur explique que ce sont les utilisateurs qui doivent se débrouiller avec l'éthique, alors que les entreprises qui créent l'IA sont laissées tranquilles. C'est un peu comme si on vendait une voiture sans freins et qu'on disait au conducteur que c'est à lui de faire attention.

« Un peuple qui ne peut plus rien croire est privé non seulement de sa capacité d’agir, mais aussi de sa capacité de penser et de juger. Et avec un tel peuple, on peut faire ce que l’on veut » ([Maurel, p. 51](zotero://select/library/items/IPC997NB)) ([pdf](zotero://open-pdf/library/items/K2ECH5ZN?page=51&annotation=M5E5K96U)) donc a partir de ca on va dire qie si l'IA aide à créer tellement de faux contenus qu'on finit par douter de tout, on perd notre capacité à juger par nous-mêmes. C'est flippant de se dire que la perte de confiance est le premier pas vers la manipulation totale.

« Il convient de distinguer plusieurs degrés de désinformation : de la mésinformation, qui désigne le partage non-intentionnel d’une fausse information ; à la désinformation brute qui désigne cette fois le partage intentionnel de cette fausse information ; jusqu’à la malveillance ou à l’influence informationnelle, qui renvoie au partage d’une information avérée mais volontairement sorti de son contexte pour tromper son destinataire. » ([Maurel, p. 51](zotero://select/library/items/IPC997NB)) ([pdf](zotero://open-pdf/library/items/K2ECH5ZN?page=51&annotation=TZ723ECL)) C'est utile de bien distinguer les trois : l'erreur (mésinformation), le mensonge volontaire (désinformation) et le vrai sorti de son contexte (malveillance). Souvent, on mélange tout sous le mot "fake news", mais les intentions ne sont pas les mêmes.

« En Roumanie, les résultats des dernières élections présidentielles ont été annulés par une décision de la Cour constitutionnelle, qui soupçonnait des irrégularités dans la sincérité des scrutin » ([Maurel, p. 52](zotero://select/library/items/IPC997NB)) ([pdf](zotero://open-pdf/library/items/K2ECH5ZN?page=52&annotation=TUXX679N)) C'est un exemple frappant et assez grave. On ne parle plus de théorie, mais d'une élection annulée à cause de TikTok et de la manipulation. Ça montre que le danger est "tangible", comme dit l'auteur : le virtuel a des conséquences réelles sur qui dirige un pays.

« d’opérations impliquant, de manière directe ou indirecte, un État étranger en visant à la diffusion artificielle, massive et délibérée, par le biais d’un service de communication au public en ligne, d’allégations de faits manifestement inexactes ou trompeuses « de nature à porter atteinte aux intérêts fondamentaux de la Nation » . » ([Maurel, p. 53](zotero://select/library/items/IPC997NB)) ([pdf](zotero://open-pdf/library/items/K2ECH5ZN?page=53&annotation=G6I8LK3V)) C'est intéressant de voir qu'il y a maintenant un service officiel (VIGINUM) et une définition légale pour ça. On ne parle plus juste de "fake news" sur Facebook, mais d'une attaque contre les "intérêts de la Nation". L'IA n'est plus un jouet, c'est une arme diplomatique et militaire pour déstabiliser un pays.

« l’Union européenne doit impérativement faire front pour préserver la qualité du débat public et les libertés qui y sont associées. » ([Maurel, p. 54](zotero://select/library/items/IPC997NB)) ([pdf](zotero://open-pdf/library/items/K2ECH5ZN?page=54&annotation=7GK7H4G3)) L'idée de "faire front" au niveau européen est intéressante. Ça montre que face à l'IA et à la désinformation, un pays seul ne peut rien faire. L'enjeu n'est pas seulement technique, c'est de protéger notre façon de vivre et nos libertés.
