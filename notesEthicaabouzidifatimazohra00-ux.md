# Annotations  
(12/02/2026 22:43:02)

« Il convient de noter cependant que ce projet de recherche n’avait pas vocation à formuler des recommandations sur les applications ellesmêmes, comme pourrait le faire un comité d’éthique. Notre travail consistait à faire apparaître dans les modélisations des agents autonomes l’axiologie, les principes éthiques et les dilemmes, ce qui ne » ([, p. 7](zotero://select/library/items/ISCR7XPK)) ([pdf](zotero://open-pdf/library/items/I76RBRC2?page=7&annotation=BNPJLA2D)) Ma lecture jusqu'à ici m’as laissé comprendre que le projet ETHICAA ne cherche pas à définir ce  qu’il faut faire ou ne pas faire avec les applications d’agents autonomes, contrairement à un comité d’éthique. Mais plutôt d’intégrer dans la conception même des systèmes des éléments comme les valeurs, les principes éthiques et les dilemmes possibles. comme jai compris  qu’ils veulent rendre visibles les tensions éthiques dans les modèles techniques, sans prétendre que cela suffira à garantir un usage éthique. Ils insistent donc sur le fait que modéliser l’éthique ne remplace pas la réflexion humaine ni l’évaluation des usages réels.

« Il faut s’interroger sur ce qu’est une « valeur » ou un « cadre éthique » codé dans une machine : il s’agit de fait d’un élément de connaissance, mis sous une forme mathématique calculable, et dont la portée et le contenu sémantique sont très restrictifs par rapport à ce qu’on entend en philosophie par valeur ou cadre éthique. Il faut donc être prudent dans l’utilisation des vocables. Les « valeurs » ou « cadres éthiques » représentés et simulés dans une machine constituent bien des représentations, des simplifications, des interprétations de concepts complexes – tout comme le sont les « émotions » que l’on peut faire simuler à un robot : en aucun cas la machine ne sera « morale » ou « éthique ». Ce chapitre présente donc les concepts principaux avec lesquels nous avons travaillé, partant des concepts les plus généraux sur la question de l’éthique jusqu’aux concepts les plus spécifiques liés à la prise de décision. » ([, p. 9](zotero://select/library/items/ISCR7XPK)) ([pdf](zotero://open-pdf/library/items/I76RBRC2?page=9&annotation=VH63CS4S)) On peut voir ici que l’auteur souligne le fait que coder des « valeurs » ou un « cadre éthique » dans une machine ne va pas rendre la machine plus éthique ou morale. pour lui ce sont juste des représentations simplifiées de concepts beaucoup plus complexes. L’auteur souligne qu’il faut être prudent avec ces termes, car réduire l’éthique à une formule mathématique ou à une ontologie peut trahir la réflexivité de l’éthique. On le voit dans les exemples qu’il mentionne, comme les drones militaires ou les voitures autonomes c’est ce qu’on a discuté pendant le cours,donc la pour l’auteur il est impossible de définir des principes éthiques universels pour toutes les situations. Cela montre bien que, malgré la modélisation technique, la réflexion humaine et le jugement contextuel restent essentiels.

« nos interactions avec des agents autonomes ne sont pas sans conséquences d’un point de vue existentiel. Toutefois, un tel horizon critique (au sens constructif du terme) doit aussi être en mesure de nous amener à considérer que dans le contexte de sociétés pluralistes, la référence à la nature sacrée de » ([, p. 9](zotero://select/library/items/ISCR7XPK)) ([pdf](zotero://open-pdf/library/items/I76RBRC2?page=9&annotation=7A93L565))

« La responsabilité, dans le langage courant, se réfère à des devoirs et obligations liés à un statut (parent, pilote d’avion, citoyen, etc.). » ([, p. 12](zotero://select/library/items/ISCR7XPK)) ([pdf](zotero://open-pdf/library/items/I76RBRC2?page=12&annotation=NVMAM622))

« Il est alors essentiel de distinguer responsabilité et culpabilité » ([, p. 12](zotero://select/library/items/ISCR7XPK)) ([pdf](zotero://open-pdf/library/items/I76RBRC2?page=12&annotation=NX9N5KC6))

« Les humains sont responsables de leurs erreurs et de leurs échecs, et coupables des fautes accomplies délibérément en sachant qu’elles étaient des fautes. Pour être moralement responsable, il doit y avoir une « intention coupable » » ([, p. 12](zotero://select/library/items/ISCR7XPK)) ([pdf](zotero://open-pdf/library/items/I76RBRC2?page=12&annotation=XRGEQ5WX))

« En revanche, le chauffard en état d’ivresse qui tue des innocents est entièrement responsable de ses actes, mais il est aussi coupable d’avoir conduit en état d’ivresse puisqu'il était conscient de boire plus que de raison avant de prendre le volant » ([, p. 12](zotero://select/library/items/ISCR7XPK)) ([pdf](zotero://open-pdf/library/items/I76RBRC2?page=12&annotation=ADP8BQKC))

« e concept de responsabilité entendu dans son usage juridique classique : en droit civil, la responsabilité se définit par l'obligation de réparer le dommage que l'on a causé à autrui ; en droit pénal, par l'obligation de supporter le châtiment. Nous pouvons, dans ce cas, observer la place qui est accordée à l'obligation : « obligation de réparer ou de subir la peine11 ». » ([, p. 13](zotero://select/library/items/ISCR7XPK)) ([pdf](zotero://open-pdf/library/items/I76RBRC2?page=13&annotation=3TK8CNM3)) cette référence base sur ce que Ricoeur a dit est pour moi assez essentiel  pour comprendre la dimension juridique classique (droit civil / droit pénal)

« L'éthique de responsabilité exige donc qu'on tienne compte des principes (éthique de conviction) mais aussi, avant toute décision, des conséquences prévisibles de l'acte envisagé (conséquentialisme). » ([, p. 13](zotero://select/library/items/ISCR7XPK)) ([pdf](zotero://open-pdf/library/items/I76RBRC2?page=13&annotation=VXZ9E23C)) Est-ce que prévoir des conséquences par calcul suffit pour parler d’éthique ?

« Les notions de responsabilité morale, d’intention, d’autonomie, de volonté dépendent toutes à des degrés divers de la notion plus fondamentale de liberté. Aussi qu’entendons-nous par liberté (libre arbitre) et dans quelle mesure est-elle applicable aux agents autonomes ? Le libre arbitre suppose que ce que je fais (mon existence) n’est pas déterminé par ce que je suis (mon essence), mais le crée, au contraire, ou le choisit librement. Cette liberté renferme l’exigence d’une autonomie absolue, c’est l’existence qui précède l’essence. » ([, p. 13](zotero://select/library/items/ISCR7XPK)) ([pdf](zotero://open-pdf/library/items/I76RBRC2?page=13&annotation=JTIP7R4B)) Cela me semble essentiel : sans liberté réelle, il devient difficile d’attribuer une responsabilité morale.

« selon Sartre, le pouvoir indéterminé de se déterminer soi-même, autrement dit de se choisir ou de se créer. » ([, p. 13](zotero://select/library/items/ISCR7XPK)) ([pdf](zotero://open-pdf/library/items/I76RBRC2?page=13&annotation=MKURRQ9L)) la lauteur a donne une autre referance par rapport a sart du fait que « l’existence précède l’essence »  la liberté comme pouvoir de se déterminer soi-même

« le libre arbitre n’existe pas. Si les humains se figurent être libres, c’est parce qu’ils ont conscience de leur désir mais ignorent tout des causes qui leur font désirer » ([, p. 13](zotero://select/library/items/ISCR7XPK)) ([pdf](zotero://open-pdf/library/items/I76RBRC2?page=13&annotation=2TTM4UFU)) apres il y a aussi cette referance de spinoza qui dit ''nous nous croyons libres parce que nous ignorons les causes qui nous déterminent''jai pu comprendre que pour lui , le libre arbitre est juste une illusion

« C’est pourquoi un agent autonome – contraint par les nécessités de sa programmation et disposant de fonctions, certes limitées, de prévision et de décision – peut être vu comme libre au sens de Spinoza mais certainement pas libre au sens de Sartre. » ([, p. 14](zotero://select/library/items/ISCR7XPK)) ([pdf](zotero://open-pdf/library/items/I76RBRC2?page=14&annotation=J586R9QB)) Donc dans se passage si on dit que  l’agent est entièrement déterminé par sa programmation, peut-on réellement parler de liberté, même au sens de Spinoza, ou s’agit-il simplement d’un déterminisme technique sophistiqué ?

« Notons toutefois qu’il s’agit là d’un abus de langage, car c’est bien plutôt d’automatismes, c’est-à-dire d’entités qui agissent sans qu’intervienne, dans le temps de l’action, une volonté extérieure, que d’autonomie au sens propre, puisque ces entités ne manifestent pas de volonté spontanée qui échapperait à leurs utilisateurs et a fortiori à leurs concepteurs. » ([, p. 14](zotero://select/library/items/ISCR7XPK)) ([pdf](zotero://open-pdf/library/items/I76RBRC2?page=14&annotation=YGC5Q5X5)) Je suis d’accord avec cette distinction entre autonomie et automatisme. L’absence de volonté spontanée montre que les systèmes dits "autonomes" restent fondamentalement dépendants de leur conception et de leur programmation initiale. Il s’agit d’une autonomie fonctionnelle et non morale.

« Le jugement est à l’origine de tout comportement rationnel ; sans lui, il n’y a ni liberté, ni éthique possible. » ([, p. 15](zotero://select/library/items/ISCR7XPK)) ([pdf](zotero://open-pdf/library/items/I76RBRC2?page=15&annotation=BI4Z345N)) ici si on pense que le jugement est la condition de la liberté et de l’éthique,comment les agents autonomes qui interprètent seulement des données peuvent  accéder à une forme d’éthique?

« Et ces deux points font appel à un jugement qui apparaît très difficile à traduire sous forme algorithmique, surtout lorsque les combattants ne portent pas d’uniforme et que la supériorité technologique » ([, p. 15](zotero://select/library/items/ISCR7XPK)) ([pdf](zotero://open-pdf/library/items/I76RBRC2?page=15&annotation=W5IQ4CMC))

« d’un camp surpasse considérablement celle de l’autre, comme c’est le cas dans les guerres asymétriques contemporaines. » ([, p. 15](zotero://select/library/items/ISCR7XPK)) ([pdf](zotero://open-pdf/library/items/I76RBRC2?page=15&annotation=3CIXFX8T)) Je suis d’accord avec cette analyse : les principes de discrimination et de proportionnalité impliquent une contextualisation complexe et une interprétation morale fine qui dépasse une simple formalisation algorithmique. Cela montre les limites structurelles de l’éthique computationnelle.

« Aujourd’hui, les finalités des agents autonomes sont fournies par le concepteur, l'usager ou d'autres agents ; leur prudence se résume donc à l’obéissance à des injonctions fixées par avance, par exemple aller d’un point A à un point B pour une voiture autonome. » ([, p. 16](zotero://select/library/items/ISCR7XPK)) ([pdf](zotero://open-pdf/library/items/I76RBRC2?page=16&annotation=K35DN3KI)) Peut-on réellement parler de prudence si les finalités ne sont jamais auto-déterminées par l’agent mais toujours imposées de l’extérieur ?

« La première distinction que nous opérons est entre morale et éthique, c’est-à-dire entre le raisonnement sur le bien et mal, et le raisonnement sur le juste et l’injuste comme vu au chapitre précédent. La seconde distinction explicite est entre éthique individuelle et éthique collective car, dans le deuxième cas, il s’agit de permettre à un agent de tenir compte de la pluralité des valeurs et principes des autres agents. » ([, p. 19](zotero://select/library/items/ISCR7XPK)) ([pdf](zotero://open-pdf/library/items/I76RBRC2?page=19&annotation=IZZ5SGKH)) ici on peut comprendre  **la structuration conceptuelle centrale** du projet ETHICAA

« Enfin, notre cadre est construit à partir d'un ensemble de fonctionnalités nécessaires au traitement d » ([, p. 19](zotero://select/library/items/ISCR7XPK)) ([pdf](zotero://open-pdf/library/items/I76RBRC2?page=19&annotation=ZJVYGVDA))

« e » ([, p. 19](zotero://select/library/items/ISCR7XPK)) ([pdf](zotero://open-pdf/library/items/I76RBRC2?page=19&annotation=97USAI74))

« l’éthique dans les systèmes d’agents autonomes : percevoir les situations de dilemme, attribuer la causalité et les responsabilités, juger, décider et agir en fonction de principes éthiques et moraux, collaborer et faire confiance aux autres agents, expliquer et justifier les décisions, et enfin être capable de vérifier formellement l'éthique du comportement d’un agent. » ([, p. 19](zotero://select/library/items/ISCR7XPK)) ([pdf](zotero://open-pdf/library/items/I76RBRC2?page=19&annotation=RFWX33D9)) Je suis d’accord avec cette approche méthodique : la décomposition des fonctions en modules précis permet non seulement de formaliser l’éthique computationnelle, mais aussi de rendre le raisonnement des agents plus transparent et vérifiable. Cela constitue une base solide pour des systèmes éthiques fiables.

« Il convient alors de définir ce que l’on entend par « insatisfaisant ». Si nous modélisons une situation comme un ensemble de décisions ayant des conséquences, nous pouvons poser l’insatisfaction pour une décision comme une disjonction entre deux conditions : 1. Les conséquences de la décision sont insatisfaisantes lorsque au moins un fait faisant partie de ses conséquences est apprécié comme négatif. 2. La décision est insatisfaisante en elle-même, c’est-à-dire qu’elle ne doit pas l’être pour ses consé » ([, p. 20](zotero://select/library/items/ISCR7XPK)) ([pdf](zotero://open-pdf/library/items/I76RBRC2?page=20&annotation=LCV32YAW))

« quences, puisque étudiées séparément, mais par sa nature. Nous pouvons imaginer une situation où « mentir » mène à un ensemble de conséquences satisfaisantes. Cependant, cette décision n’est pas satisfaisante car la décision en elle-même est appréciée négativement. Notons que dans les deux cas il s’agit d’une appréciation propre à l’agent qui juge la décision. Qu’il s’agisse d’identifier un dilemme ou de raisonner sur ce dilemme, il est important de toujours garder à l’esprit les l » ([, p. 20](zotero://select/library/items/ISCR7XPK)) ([pdf](zotero://open-pdf/library/items/I76RBRC2?page=20&annotation=SNRYA93L)) Comment un agent autonome peut-il réellement juger qu’une décision est « insatisfaisante en elle-même », si cette appréciation relève d’un jugement moral subjectif ?

« Déterminer cela demande d’évaluer l’importance de chaque critère pour choisir une cause première. À l’inverse, nous pouvons considérer que dans la mesure où tous ces éléments participent d’une façon ou d’une autre au résultat final, ils peuvent tous être considérés comme des causes. » ([, p. 21](zotero://select/library/items/ISCR7XPK)) ([pdf](zotero://open-pdf/library/items/I76RBRC2?page=21&annotation=L239QFVX)) Je suis d’accord : l’attribution de la causalité n’est jamais triviale. L’approche combinant cause première et causalité partagée reflète la complexité du raisonnement éthique et juridique, et c’est exactement ce que tout système autonome doit intégrer pour évaluer correctement responsabilités et conséquences.

« Au sein même d’un agent, nous représentons la prise de décision éthique en adjoignant au modèle du bien et au modèle du juste deux autres modèles interdépendants qui permettent à l’agent d’évaluer son environnement et de raisonner sur sa responsabilité. Ces deux modèles sont : (1) un modèle d’action permettant à l’agent de représenter son environnement et les changements qui s’y déroulent ; (2) un modèle de causalité qui piste les conséquences des actions, rendant possible un raisonnement sur l’imputabilité des agents. Ces deux modèles produisent une compréhension du monde qui ne fait pas intervenir de considérations éthiques, à la différence des deux modèles de la théorie du bien et de la théorie du juste qui superposent une compréhension éthique du monde. Les différents modèles sont interdépendants à des degrés variables. » ([, p. 24](zotero://select/library/items/ISCR7XPK)) ([pdf](zotero://open-pdf/library/items/I76RBRC2?page=24&annotation=C5WT8IIC)) Je suis d’accord : la distinction entre modèles de base (action et causalité) et modèles éthiques (bien et juste) est fondamentale. Elle montre comment une architecture réflexive peut intégrer l’éthique sans perdre la structure causale nécessaire pour raisonner sur le monde réel.

« La notion de justice prédictive peut s’entendre d’au moins trois façons, selon que l’on s’intéresse au jugement, auquel cas cela peut avoir deux significations, ou à la législation. Nous nous intéresserons ici deux premiers volets qui portent l’un et l’autre sur la façon dont la prédiction pourrait être prise en considération dans l’acte de juger, car le troisième, à savoir l’intervention de l’anticipation dans l’élaboration des lois, va bien au-delà de nos compétences et de notre propo » ([, p. 25](zotero://select/library/items/ISCR7XPK)) ([pdf](zotero://open-pdf/library/items/I76RBRC2?page=25&annotation=8AR9DSRY)) Comment concilier l’efficacité potentielle de la justice prédictive avec les principes fondamentaux de liberté, de présomption d’innocence et de possibilité de réhabilitation ?

« Plus généralement, l’usage quasiment systématique du profilage des identités exclut le changement de cap et le décentrement, éliminant, de ce fait, la possibilité d’explorer différents modes d’action. Dans le cadre du projet ETHICAA, nous nous sommes centrés sur la problématisation et la modélisation de conflits éthiques, sans travailler directement sur les questions d'apprentissage et de profilage. » ([, p. 25](zotero://select/library/items/ISCR7XPK)) ([pdf](zotero://open-pdf/library/items/I76RBRC2?page=25&annotation=WFIWHE5W)) ce passage est important dans la mesure ou il nous montre  
 les limites techniques et éthiques de la **prédiction comportementale**

« Dans ce contexte, un agent doit non seulement tenir compte de principes éthiques au regard de ses propres objectifs mais aussi quant à la manière dont il coopère, et par extension quant à la manière dont il tient compte des principes éthiques des autres agents. Dans le cadre du projet ETHICAA, deux directions de recherche d’agents autonomes avec » ([, p. 26](zotero://select/library/items/ISCR7XPK)) ([pdf](zotero://open-pdf/library/items/I76RBRC2?page=26&annotation=7DX3QNS6))

« une pluralité d’éthiques ont été initiées dans un cadre multiagent : jugement de l’éthique des autres pour coopérer et formation éthique de collectifs d’agents. » ([, p. 26](zotero://select/library/items/ISCR7XPK)) ([pdf](zotero://open-pdf/library/items/I76RBRC2?page=26&annotation=FTER8DJV)) Ce passage souligne la complexité des systèmes multi-agents : la coopération éthique nécessite non seulement un jugement sur ses propres actions mais aussi sur celles des autres, ce qui introduit des incertitudes et des risques d’interprétation erronée. La modélisation des niveaux de connaissance (aveugle, partiellement informé, totalement informé) est essentielle pour gérer cette complexité.

« Ce processus se traduit par un calcul de la confiance et de la proximité éthique entre les agents. Cela permet ensuite à chaque agent de décider de coopérer ou non avec d’autres agents et de potentiellement leur déléguer la réalisation de certaines actions. Ce travail a été testé et validé sur la vente et l’achat de biens financiers sur une place de marché simulée. » ([, p. 27](zotero://select/library/items/ISCR7XPK)) ([pdf](zotero://open-pdf/library/items/I76RBRC2?page=27&annotation=BXYV8NM5)) Cette partie soulève un défi clé pour l’éthique computationnelle : la génération d’explications éthiques exploitables par un humain nécessite de condenser un raisonnement complexe, contextuel et multi-agent en éléments compréhensibles. Cela illustre la tension entre transparence, explicabilité et complexité des systèmes autonomes.

« Dans le cadre de la formation éthique de collectifs d’agents, c’està-dire de groupes d’agents qui vont devoir par la suite collaborer pour effectuer une action, nous avons proposé une modélisation d’une éthique du bien fondée sur les vertus. Pour ce faire, nous avons proposé un nouveau modèle de jeux de coalitions – les jeux de déviation hédoniques – où chaque agent exprime des conditions qui lui sont propres pour caractériser la manière dont il tient compte des autres agents. Nous avons formellement défini ce qu’était une solution d’un tel jeu qui faisait consensus entre tous les agents et nous avons montré que certaines compositions de conditions permettent de retrouver les solutions classiques de la littérature. Nous avons alors pu nous servir de notre modèle pour caractériser trois éthiques fondées sur des vertus : la liberté, l’altruisme et l’hédonisme » ([, p. 27](zotero://select/library/items/ISCR7XPK)) ([pdf](zotero://open-pdf/library/items/I76RBRC2?page=27&annotation=J96D6695)) ici c'etais pour introduit un **modèle formel de formation éthique de collectifs**, une innovation méthodologique

« En effet, cette technique représente les arguments pour et contre les différentes décisions possibles et calcule un ensemble d’arguments acceptables au regard d’une certaine sémantique. Les arguments sont représentés dans une structure hiérarchique qu’un utilisateur peut parcourir pour avoir de plus en plus d’arguments spécifiques. » ([, p. 28](zotero://select/library/items/ISCR7XPK)) ([pdf](zotero://open-pdf/library/items/I76RBRC2?page=28&annotation=DD46AQPG)) Je suis d’accord : la hiérarchisation des arguments permet de rendre le raisonnement éthique transparent et progressif. Cela facilite la compréhension humaine et l’acceptation des décisions d’un agent autonome, tout en conservant la complexité nécessaire pour modéliser les dilemmes éthiques.

« Enfin, produire des justifications au sein d’un système multiagent pose de nouvelles questions. En effet, en raison de la nature distribuée, décentralisée, voire hétérogène et ouverte, de tels systèmes, il convient de se demander : comment justifier une décision lorsqu’elle est influencée par les décisions d’autres agents ? Comment réutiliser des justifications fournies par un autre agent ? Comment faire lorsqu’un agent est incapable de fournir sa part de justification ? » ([, p. 29](zotero://select/library/items/ISCR7XPK)) ([pdf](zotero://open-pdf/library/items/I76RBRC2?page=29&annotation=L2WH77SS)) Comment gérer la responsabilité et la traçabilité des décisions dans un système multi-agent lorsque les justifications sont distribuées et potentiellement incomplètes ?

« Nous avons donc proposé un environnement de spécification et de vérification formelle du comportement éthique d’un agent autonome. » ([, p. 29](zotero://select/library/items/ISCR7XPK)) ([pdf](zotero://open-pdf/library/items/I76RBRC2?page=29&annotation=84NBQFDX)) Je suis d’accord : formaliser et vérifier l’éthique d’un agent est indispensable pour garantir qu’un agent autonome respecte les règles morales dans tous les contextes possibles. Cela assure la **fiabilité et la sécurité des systèmes autonomes**, surtout dans des environnements complexes et critiques.

« l’ensemble des machines doit toujours supposer l’humain comme interprète vivant des machines les unes par rapport aux autres : « Loin d’être le surveillant d’une troupe d’esclaves, l’est l’organisateur permanent d’une société des objets techniques qui ont besoin de lui comme les musiciens ont besoin du chef d’orchestre15 ». » ([, p. 32](zotero://select/library/items/ISCR7XPK)) ([pdf](zotero://open-pdf/library/items/I76RBRC2?page=32&annotation=LT9Q7GW2)) Je suis d’accord : cette référence à Simondon rappelle que les systèmes techniques ne doivent pas remplacer l’humain mais s’inscrire dans une relation d’interprétation et de coordination. Cela correspond parfaitement à l’exigence d’intelligibilité dans la conception des agents autonomes.

« un enjeu éthique de premier ordre sera de concevoir des interactions où les usagers seront, autant que possible, en situation de participation cognitive et intellectuelle, et où l’exercice du librearbitre demeurera aussi entier que possible, en reprenant la main sur les systèmes, en étant capables, par exemple, de neutraliser un système de géolocalisation. » ([, p. 32](zotero://select/library/items/ISCR7XPK)) ([pdf](zotero://open-pdf/library/items/I76RBRC2?page=32&annotation=BIZ3PJC4)) Comment garantir une véritable participation cognitive des usagers lorsque les systèmes deviennent de plus en plus complexes et autonomes ? L’intelligibilité technique suffit-elle à préserver le libre arbitre ?

« même dans le cadre conséquentialiste, les quantifications peuvent mener à de dangereuses comparaisons entre faits incomparables, de par leur réduction à de simples chiffres. » ([, p. 33](zotero://select/library/items/ISCR7XPK)) ([pdf](zotero://open-pdf/library/items/I76RBRC2?page=33&annotation=4GBYXPAA)) Je suis d’accord : réduire des réalités qualitativement différentes à des valeurs numériques crée l’illusion d’objectivité. Cela peut masquer des choix normatifs implicites derrière des calculs apparemment neutres.

« il paraît essentiel d’adopter une démarche modulaire séparant clairement les différents aspects du raisonnement. En particulier, il convient non seulement d’identifier précisément les aspects relevant purement de l'éthique, mais aussi de bien mettre en évidence les éléments sur lesquels ils se fondent, pour mieux en cerner les dépendances. » ([, p. 33](zotero://select/library/items/ISCR7XPK)) ([pdf](zotero://open-pdf/library/items/I76RBRC2?page=33&annotation=JH69KVEG)) ce passage est omportant dans la mesur ou il introduit un principe méthodologique central : **la modularité**

« C » ([, p. 34](zotero://select/library/items/ISCR7XPK)) ([pdf](zotero://open-pdf/library/items/I76RBRC2?page=34&annotation=HQJ73A5E))

« ette pluralité peut être accrue en envisageant la dimension organisationnelle des systèmes multiagents qui vient structurer les agents et leurs coopérations selon les organisations auxquelles ils appartiennent. Les agents d’une même organisation pourront ainsi intégrer des théories du bien et du juste soutenues par l’organisation à laquelle ils appartiennent. Ces théories seront à intégrer et à concilier éventuellement avec leurs propres théories. Un agent appartenant à plusieurs organisations pourra ainsi également développer différents comportements éthiques selon l’organisation à laquelle il se réfère en cours d’exécution. » ([, p. 34](zotero://select/library/items/ISCR7XPK)) ([pdf](zotero://open-pdf/library/items/I76RBRC2?page=34&annotation=7EM3A6G2)) Comment gérer les conflits entre les théories éthiques propres à l’agent et celles imposées par une organisation, surtout si leurs principes du bien et du juste sont incompatibles ?

« les algorithmes peuvent paraître permettre une décision humaine plus objective mais ils sont eux-même soumis à la subjectivité de ceux qui les ont conçus. » ([, p. 35](zotero://select/library/items/ISCR7XPK)) ([pdf](zotero://open-pdf/library/items/I76RBRC2?page=35&annotation=H5XBV25V)) Pointe la tension majeure entre **éthique (ouverte, contextuelle, interprétative)** et **certification formelle (rigoureuse, déterminée, stable)**

« De plus, le risque de déléguer à une machine des choix qui, au plan éthique, relèvent de la subjectivité humaine est a priori problématique. » ([, p. 35](zotero://select/library/items/ISCR7XPK)) ([pdf](zotero://open-pdf/library/items/I76RBRC2?page=35&annotation=9244CWAX))

« Dans l’ensemble des travaux liés à la modélisation de l’éthique, le contexte est pratiquement toujours réduit à la situation. Cette simplification est un argument supplémentaire à la thèse soutenant qu’un système autonome ne peut avoir un raisonnement éthique à proprement parler, mais peut seulement embarquer des concepts éthiques dans son raisonnement. » ([, p. 40](zotero://select/library/items/ISCR7XPK)) ([pdf](zotero://open-pdf/library/items/I76RBRC2?page=40&annotation=AYQQYDVD)) Si le contexte est historiquement, socialement et temporellement structuré, est-il seulement possible de le formaliser sans le réduire à un ensemble fini de variables observables ?

« les décisions pouvant être prises en fonction du contexte sont calculées au préalable et embarquées au sein de l’agent par exemple sous forme d’arbres de décision. Toutefois, l’agent n’est pas à l’abri de se retrouver dans un contexte imprévu. Dans ce cas, une approche possible serait d’apprendre à l’aide d’un réseau de neurones le résultat du raisonnement éthique afin de le généraliser. » ([, p. 41](zotero://select/library/items/ISCR7XPK)) ([pdf](zotero://open-pdf/library/items/I76RBRC2?page=41&annotation=ER3SW573)) Introduit une approche d’**éthique compilée** (offline reasoning).

« Il convient cependant de faire attention ici aux problèmes des cas particuliers qui pourraient ne pas être pris en considération par une généralisation. En effet, l’éthique s’accommode mal des généralisations hâtives. » ([, p. 41](zotero://select/library/items/ISCR7XPK)) ([pdf](zotero://open-pdf/library/items/I76RBRC2?page=41&annotation=7JYRL8MX)) Je suis d’accord : l’apprentissage par généralisation (ex. réseaux de neurones) risque d’effacer la singularité des cas particuliers, alors que l’éthique exige précisément une attention au contexte et aux exceptions.

« Ce trafic mixte impose que les véhicules autonomes soient capables de prendre en compte des comportements non rationnels. Considérer que ce problème disparaîtra avec la fin de la mixité est illusoire. L’accident du dimanche 18 mars 2018 provoquant la mort d’une cycliste par un véhicule » ([, p. 42](zotero://select/library/items/ISCR7XPK)) ([pdf](zotero://open-pdf/library/items/I76RBRC2?page=42&annotation=CL8HAKLM)) la modélisation d’un environnement purement rationnel est irréaliste. L’intégration de comportements humains imprévisibles est une condition nécessaire à toute éthique embarquée crédible.

« Quel référentiel d'exigences considérer ? Un seul ou plusieurs ? » ([, p. 43](zotero://select/library/items/ISCR7XPK)) ([pdf](zotero://open-pdf/library/items/I76RBRC2?page=43&annotation=SR7DMNL3)) Peut-on concevoir une certification éthique universelle pour des systèmes autonomes opérant dans des contextes culturels, juridiques et sociaux hétérogènes ?

« L'éthique d'un comportement ne peut se concevoir qu'en contexte. Il s'agit ici de capter les particularités du contexte et de la situation dans lesquels le comportement doit être mis en œuvre et pour lesquels son éthique doit pouvoir être évaluée » ([, p. 43](zotero://select/library/items/ISCR7XPK)) ([pdf](zotero://open-pdf/library/items/I76RBRC2?page=43&annotation=E4U2WYQB)) une exigence éthique abstraite n’a pas de signification indépendante du contexte d’application. La certification doit donc intégrer des scénarios contextualisés et non de simples critères génériques.

« le projet ETHICAA a produit un cadre de raisonnement éthique fondé sur une approche symbolique de l’Intelligence Artificielle pour permettre à un agent autonome d’évaluer son environnement, d’intégrer des principes éthiques et de déterminer, à partir de la mise en œuvre de ces principes, soit un plan d’actions, soit une évaluation du comportement d’autres agents. Au-delà de ces réalisations techniques et des recommandations que nous avons formulées, nous avons pu nous rendre compte qu’il importe de pouvoir s’entendre sur certaines valeurs afin de stimuler une évaluation des innovations technologiques dans le » ([, p. 47](zotero://select/library/items/ISCR7XPK)) ([pdf](zotero://open-pdf/library/items/I76RBRC2?page=47&annotation=NG73BJSM)) Résume l’apport technique central du projet : un cadre symbolique capable de gérer à la fois l’auto-évaluation éthique et l’évaluation des autres agents, ce qui structure l’ensemble du raisonnement multi-agent

« ’il importe de pouvoir s’entendre sur certaines valeurs afin de stimuler une évaluation des innovations technologiques dans les contextes où elles sont utilisées. » ([, p. 47](zotero://select/library/items/ISCR7XPK)) ([pdf](zotero://open-pdf/library/items/I76RBRC2?page=47&annotation=GQJH4A7N)) ce passage Met en avant l’importance de la **dimension intersubjective** de l’éthique : la discussion collective et la confrontation d’arguments sont essentielles pour orienter les systèmes autonomes vers des choix responsables.
