# Annotations  
(12/02/2026 13:21:46)

« il n’y a pas de lien de nécessité entre « progrès technologique » et « progrès social ». » ([“Ethique et agents autonomes”, p. 5](zotero://select/library/items/QKIUDDZY)) ([pdf](zotero://open-pdf/library/items/SSI9SCBN?page=5&annotation=H5F8YSZM)) Je me questionne sur cette affirmation qui semble radicale. Si le lien n’est pas nécessaire, il est néanmoins fréquent historiquement. Certaines avancées technologiques ont effectivement favorisé le progrès social (médecine, communication, accès à l’information). La question serait donc plutôt : sous quelles conditions le progrès technologique devient-il progrès social ?

« L’éthique nous invite à intégrer le fait que ce qui est technologiquement possible n’est pas toujours humainement ou socialement souhaitable » ([“Ethique et agents autonomes”, p. 5](zotero://select/library/items/QKIUDDZY)) ([pdf](zotero://open-pdf/library/items/SSI9SCBN?page=5&annotation=NCU4L4WP)) Je suis totalement d’accord avec cette affirmation car elle rappelle que l’innovation technologique ne peut être évaluée uniquement selon des critères de performance ou d’efficacité. Elle introduit une distinction essentielle entre faisabilité technique et désirabilité sociale, ce qui constitue le cœur même d’une réflexion éthique sur l’IA.

« La morale se présente comme un ensemble de règles contraignantes d’un type spécial, qui consiste à juger des actions et des intentions en les rapportant à des valeurs transcendantes (c’est bien, c’est mal...) ; l’éthique est un ensemble de règles facultatives » ([“Ethique et agents autonomes”, p. 6](zotero://select/library/items/QKIUDDZY)) ([pdf](zotero://open-pdf/library/items/SSI9SCBN?page=6&annotation=QP2KY3SA)) Cette référence est centrale car elle structure toute la distinction conceptuelle du document. Elle permet de comprendre pourquoi le projet ETHICAA privilégie une approche réflexive plutôt que prescriptive. Cette distinction est fondamentale pour toute recherche en éthique appliquée aux technologies.

« Une éthique - car il y en a dès lors plusieurs - ne répond pas à la question « Que dois-je faire ? », mais à la question « Comment vivre ? » » ([“Ethique et agents autonomes”, p. 6](zotero://select/library/items/QKIUDDZY)) ([pdf](zotero://open-pdf/library/items/SSI9SCBN?page=6&annotation=653C25NM)) Cette formulation met en lumière la dimension existentielle de l’éthique. Elle montre que l’éthique dépasse la simple conformité à des règles pour interroger les modes de vie. Cela est particulièrement pertinent dans le contexte des agents autonomes qui influencent nos comportements quotidiens.

« si on résume l’éthique à un problème de logique, cela devient plus que problématique » ([“Ethique et agents autonomes”, p. 10](zotero://select/library/items/QKIUDDZY)) ([pdf](zotero://open-pdf/library/items/SSI9SCBN?page=10&annotation=9N37NRRW)) je me questionne ici car dans le cadre de l’intelligence artificielle une formalisation logique semble inévitable.

« Il n’y a pas d’ontologie de l’éthique » ([“Ethique et agents autonomes”, p. 11](zotero://select/library/items/QKIUDDZY)) ([pdf](zotero://open-pdf/library/items/SSI9SCBN?page=11&annotation=BS3FINE6)) je ne suis pas totalement d’accord avec cette affirmation. Même si l’éthique ne peut être réduite à une ontologie stricte, de nombreux travaux en IA cherchent précisément à formaliser des concepts éthiques sous forme d’ontologies computationnelles

« Morale Éthique Champ d'application prétendu universel Champ d'application particulier Statut absolu Statut relatif Modalité impérative Modalité hypothétique Principe du devoir Principe du désir Visée de la vie bonne Visée de la vie juste Tout discours normatif et impératif : o opposition du bien et du mal o devoirs universels et inconditionnels Tout discours normatif et hypothétique : o opposition du bon et du mauvais o valeurs immanentes et relatives » ([“Ethique et agents autonomes”, p. 11](zotero://select/library/items/QKIUDDZY)) ([pdf](zotero://open-pdf/library/items/SSI9SCBN?page=11&annotation=EWJAB488)) Ce tableau constitue un outil conceptuel fondamental pour comprendre l’architecture théorique du projet. Il synthétise la distinction entre universel/particulier, absolu/relatif, impératif/hypothétique. Il peut servir de base méthodologique pour toute analyse comparative.

« être responsable c’est pouvoir et devoir répondre de ses actes en assumant 12 8 Paul Ricœur. Dictionnaire d'éthique et de philosophie morale. 2014. 9 Hans Jonas. Le principe responsabilité. 2013. « le pouvoir qui est le sien » ([“Ethique et agents autonomes”, p. 12](zotero://select/library/items/QKIUDDZY)) ([pdf](zotero://open-pdf/library/items/SSI9SCBN?page=12&annotation=4FUYPA2D)) Cette définition est particulièrement pertinente dans le débat sur la responsabilité des agents autonomes. Elle souligne que la responsabilité implique la capacité d’agir autrement.

« Le jugement est à l’origine de tout comportement rationnel ; sans lui, il n’y a ni liberté, ni éthique possible. » ([“Ethique et agents autonomes”, p. 15](zotero://select/library/items/QKIUDDZY)) ([pdf](zotero://open-pdf/library/items/SSI9SCBN?page=15&annotation=ASJQZFMF)) Je m’interroge sur cette affirmation dans le contexte de l’apprentissage automatique. Certains systèmes prennent des décisions sans passer par un “jugement” au sens classique

« a modélisation de la moralité fait l’objet de recherches plus récentes » ([“Ethique et agents autonomes”, p. 16](zotero://select/library/items/QKIUDDZY)) ([pdf](zotero://open-pdf/library/items/SSI9SCBN?page=16&annotation=MRPTG8PM)) Cette remarque souligne l’actualité scientifique du sujet. Elle montre que l’éthique computationnelle est encore en construction, ce qui justifie l’importance du projet ETHICAA et des recherches interdisciplinaires.

« l’axiologie et le traitement des valeurs doivent déboucher sur des définitions formelles explicites ou des taxonomies utilisables en Intelligence Artificielle. » ([“Ethique et agents autonomes”, p. 17](zotero://select/library/items/QKIUDDZY)) ([pdf](zotero://open-pdf/library/items/SSI9SCBN?page=17&annotation=9AX8HCVK)) Cette phrase est stratégique, . Elle légitime l’idée qu’une réflexion théorique doit aboutir à des outils opérationnels

« il s’agit de permettre à un agent de tenir compte de la pluralité des valeurs et principes des autres agents. » ([“Ethique et agents autonomes”, p. 19](zotero://select/library/items/QKIUDDZY)) ([pdf](zotero://open-pdf/library/items/SSI9SCBN?page=19&annotation=D5XF75KC)) Cette phrase est centrale car elle introduit la dimension multi-agent et le pluralisme éthique. Elle est fondamentale pour comprendre que l’éthique computationnelle ne peut pas être uniquement individuelle mais doit intégrer la diversité des systèmes de valeurs.

« percevoir les situations de dilemme, attribuer la causalité et les responsabilités, juger, décider et agir en fonction de principes éthiques et moraux » ([“Ethique et agents autonomes”, p. 19](zotero://select/library/items/QKIUDDZY)) ([pdf](zotero://open-pdf/library/items/SSI9SCBN?page=19&annotation=6EEDGIR3)) Cette liste structure clairement les étapes d’un raisonnement éthique artificiel. Elle montre que l’éthique n’est pas une couche ajoutée après coup mais un processus intégré dans toute la chaîne décisionnelle.

« un dilemme se définit par l’absence de « bonne solution ». » ([“Ethique et agents autonomes”, p. 20](zotero://select/library/items/QKIUDDZY)) ([pdf](zotero://open-pdf/library/items/SSI9SCBN?page=20&annotation=CFHATLRT)) Je m’interroge sur cette définition car elle suppose une conception assez binaire du jugement moral. Peut-on réellement affirmer qu’il n’existe aucune “meilleure” solution même si toutes sont imparfaites ?

« il est important de toujours garder à l’esprit les limites de perception d’un agent. » ([“Ethique et agents autonomes”, p. 20](zotero://select/library/items/QKIUDDZY)) ([pdf](zotero://open-pdf/library/items/SSI9SCBN?page=20&annotation=FHSG6SMB)) Cette remarque est essentielle car elle rappelle que toute décision éthique dépend des données disponibles. Un défaut de perception peut produire une décision moralement problématique, même si le raisonnement interne est cohérent.

« A est une cause de B quand, si A n’était pas arrivé, B ne serait pas arrivé non plus. » ([“Ethique et agents autonomes”, p. 21](zotero://select/library/items/QKIUDDZY)) ([pdf](zotero://open-pdf/library/items/SSI9SCBN?page=21&annotation=JEQVL5GF)) Cette référence à la causalité contre-factuelle (Hume) est importante car elle montre la difficulté d’attribuer une responsabilité dans des systèmes complexes. Elle éclaire les limites d’un raisonnement simpliste en matière de causalité.

« selon Hume, Suzy n’a pas causé le bris de la bouteille » ([“Ethique et agents autonomes”, p. 22](zotero://select/library/items/QKIUDDZY)) ([pdf](zotero://open-pdf/library/items/SSI9SCBN?page=22&annotation=RFYAGY5P)) Je ne suis pas d’accord avec cette conséquence logique appliquée strictement. Même si une autre cause était possible, l’action effective reste moralement imputable. Cette position montre les limites d’une définition purement contre-factuelle de la causalité.

« En effet, là encore, suivant les situations, le respect d’une règle morale peut devenir plus ou moins prioritaire. » ([“Ethique et agents autonomes”, p. 29](zotero://select/library/items/QKIUDDZY)) ([pdf](zotero://open-pdf/library/items/SSI9SCBN?page=29&annotation=JVDKV3MW)) Je valide cette approche car une éthique rigide et fixe est inapplicable dans la réalité. Ce qui est prioritaire dans une situation d'urgence médicale ne l'est pas dans un contexte commercial.

« un raisonnement prenant en compte des considérations éthiques ne saurait être projeté dans l’ensemble des nombres réels. » ([“Ethique et agents autonomes”, p. 33](zotero://select/library/items/QKIUDDZY)) ([pdf](zotero://open-pdf/library/items/SSI9SCBN?page=33&annotation=V6PBAYSJ)) Bien que l'auteur mette en garde contre le réductionnisme, je conteste l'idée qu'on ne puisse pas utiliser de modèles mathématiques continus. Pour qu'une machine décide en millisecondes, la quantification est souvent le seul vecteur efficace, même si elle est imparfaite.

« De plus, il y a un paradoxe consistant à calquer le raisonnement humain, qui est faillible, dans un algorithme, et vouloir que cet algorithme soit infaillible. » ([“Ethique et agents autonomes”, p. 35](zotero://select/library/items/QKIUDDZY)) ([pdf](zotero://open-pdf/library/items/SSI9SCBN?page=35&annotation=KK8LK4BF)) Je m'interroge sur la finalité, si nous ne cherchons pas l'infaillibilité, quel est l'intérêt de déléguer ces décisions à des agents autonomes ?

« Dans l’ensemble des travaux liés à la modélisation de l’éthique, le contexte est pratiquement toujours réduit à la situation. » ([“Ethique et agents autonomes”, p. 40](zotero://select/library/items/QKIUDDZY)) ([pdf](zotero://open-pdf/library/items/SSI9SCBN?page=40&annotation=LN4X5G7D)) C'est une critique fondamentale du champ de recherche actuel. Cette distinction entre "situation" (instantanée) et "contexte" (historique, social, culturel) est essentielle pour comprendre les limites actuelles de l'IA.

« et c’est certainement ce qui apportera le plus de confiance en de tels systèmes, en rendant le code des agents en question « open source ». » ([“Ethique et agents autonomes”, p. 44](zotero://select/library/items/QKIUDDZY)) ([pdf](zotero://open-pdf/library/items/SSI9SCBN?page=44&annotation=98PMYB9I)) L'auditabilité publique est la seule garantie réelle contre les biais cachés. Le secret industriel ne devrait pas prévaloir sur les décisions éthiques impactant la collectivité.
